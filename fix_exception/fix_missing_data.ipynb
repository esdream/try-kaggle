{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/'\n",
    "\n",
    "def maybe_download(filename):\n",
    "    file_csv = os.path.splitext(filename)[0] + '.csv'\n",
    "    if(not os.path.exists(file_csv)):\n",
    "        urlretrieve(url + filename, filename)\n",
    "        os.rename(filename, os.path.splitext(filename)[0] + '.csv')\n",
    "    return file_csv\n",
    "    \n",
    "diabetes_csv = maybe_download('pima-indians-diabetes.data')\n",
    "diabetes = pd.read_csv(diabetes_csv, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3           4           5  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "                6           7           8  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: 8, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每一种类变量的总数。0类是糖尿病阴性，1类是糖尿病阳性\n",
    "diabetes[8].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1   2   3    4     5      6   7  8\n",
       "0    6  148  72  35    0  33.6  0.627  50  1\n",
       "1    1   85  66  29    0  26.6  0.351  31  0\n",
       "2    8  183  64   0    0  23.3  0.672  32  1\n",
       "3    1   89  66  23   94  28.1  0.167  21  0\n",
       "4    0  137  40  35  168  43.1  2.288  33  1\n",
       "5    5  116  74   0    0  25.6  0.201  30  0\n",
       "6    3   78  50  32   88  31.0  0.248  26  1\n",
       "7   10  115   0   0    0  35.3  0.134  29  0\n",
       "8    2  197  70  45  543  30.5  0.158  53  1\n",
       "9    8  125  96   0    0   0.0  0.232  54  1\n",
       "10   4  110  92   0    0  37.6  0.191  30  0\n",
       "11  10  168  74   0    0  38.0  0.537  34  1\n",
       "12  10  139  80   0    0  27.1  1.441  57  0\n",
       "13   1  189  60  23  846  30.1  0.398  59  1\n",
       "14   5  166  72  19  175  25.8  0.587  51  1\n",
       "15   7  100   0   0    0  30.0  0.484  32  1\n",
       "16   0  118  84  47  230  45.8  0.551  31  1\n",
       "17   7  107  74   0    0  29.6  0.254  31  1\n",
       "18   1  103  30  38   83  43.3  0.183  33  0\n",
       "19   1  115  70  30   96  34.6  0.529  32  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d3c6275278>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d3c55d15c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 由于1，2，3，4，5列存在缺失值且缺失值标记为0，因此绘制的箱形图是不准确的。这里仅做示例用\n",
    "sns.boxplot(data=diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计每一列中丢失值的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((diabetes[[1, 2, 3, 4, 5]] == 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的统计可以看出，第1，2，5列只有几个零值，而第3列和第4列几乎一半行都是零值。\n",
    "在Pandas, Numpy和sklearn中，我们将将丢失值标记为NaN。那么sum，count等操作中NaN的值将会被忽略。\n",
    "通过pandas dataframe的`replace()`函数，可以将丢失值标记为NaN。\n",
    "标记了丢失值后，可以使用`isnull()`函数将数据中所有的NaN值标记为真，并获取每列丢失值的计数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      5\n",
       "2     35\n",
       "3    227\n",
       "4    374\n",
       "5     11\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes[[1,2,3,4,5]] = diabetes[[1,2,3,4,5]].replace(0, np.NaN)\n",
    "diabetes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3      4     5      6   7  8\n",
       "0    6  148.0  72.0  35.0    NaN  33.6  0.627  50  1\n",
       "1    1   85.0  66.0  29.0    NaN  26.6  0.351  31  0\n",
       "2    8  183.0  64.0   NaN    NaN  23.3  0.672  32  1\n",
       "3    1   89.0  66.0  23.0   94.0  28.1  0.167  21  0\n",
       "4    0  137.0  40.0  35.0  168.0  43.1  2.288  33  1\n",
       "5    5  116.0  74.0   NaN    NaN  25.6  0.201  30  0\n",
       "6    3   78.0  50.0  32.0   88.0  31.0  0.248  26  1\n",
       "7   10  115.0   NaN   NaN    NaN  35.3  0.134  29  0\n",
       "8    2  197.0  70.0  45.0  543.0  30.5  0.158  53  1\n",
       "9    8  125.0  96.0   NaN    NaN   NaN  0.232  54  1\n",
       "10   4  110.0  92.0   NaN    NaN  37.6  0.191  30  0\n",
       "11  10  168.0  74.0   NaN    NaN  38.0  0.537  34  1\n",
       "12  10  139.0  80.0   NaN    NaN  27.1  1.441  57  0\n",
       "13   1  189.0  60.0  23.0  846.0  30.1  0.398  59  1\n",
       "14   5  166.0  72.0  19.0  175.0  25.8  0.587  51  1\n",
       "15   7  100.0   NaN   NaN    NaN  30.0  0.484  32  1\n",
       "16   0  118.0  84.0  47.0  230.0  45.8  0.551  31  1\n",
       "17   7  107.0  74.0   NaN    NaN  29.6  0.254  31  1\n",
       "18   1  103.0  30.0  38.0   83.0  43.3  0.183  33  0\n",
       "19   1  115.0  70.0  30.0   96.0  34.6  0.529  32  1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺失值导致的问题\n",
    "数据集中存在缺失值时可能会导致机器学习算法发生错误。\n",
    "例如以下的LDA算法，当数据集中存在缺失值时，直接运行该算法会报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-0930451a34f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearDiscriminantAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    319\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    322\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             return_times=True)\n\u001b[1;32m--> 195\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mTarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \"\"\"\n\u001b[1;32m--> 429\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    541\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    543\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mI:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    420\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    421\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     41\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     42\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 43\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# split diabetes data into inputs and outputs\n",
    "values = diabetes.values\n",
    "X = values[:, 0:8]\n",
    "y = values[:, 8]\n",
    "# evaluate an LDA model on the diabetes data using k-fold cross validation\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理缺失值的方法\n",
    "#### 删除丢失行\n",
    "这是最简单的方法。pandas中的`dropna()`函数可以用于删除缺少数据的行或列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "diabetes_dropna = diabetes.dropna()\n",
    "print(diabetes_dropna.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重新运行上面的LDA模型，顺利通过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78582892934\n"
     ]
    }
   ],
   "source": [
    "# split diabetes data into inputs and outputs\n",
    "values = diabetes_dropna.values\n",
    "X = values[:, 0:8]\n",
    "y = values[:, 8]\n",
    "# evaluate an LDA model on the diabetes data using k-fold cross validation\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 估算丢失值\n",
    "替换较少的值时可以有很多考虑。例如：\n",
    "+ 在域内具有含义的常量值，例如不同于其他所有的值\n",
    "+ 来自另一个随机记录的值\n",
    "+ 该列的均值、中值或众数值\n",
    "+ 由另一种预测模型估计的值\n",
    "\n",
    "pandas中提供了`fillna()`函数来替换具有特定值的丢失值\n",
    "`fillna()`中提供了一些填充丢失值的方法（通过`method`参数指定），也可以指定填充的缺失值。例如以前一个未缺失数据填充`method='pad'`（pad和ffill效果相同），以后一个未缺失数据填充`method='ffill'`（backfill和bfill效果相同）。\n",
    "\n",
    "另一个需要注意的是`fillna()`中的`limit`参数。它限制了一段连续缺失值中填充的个数。默认为None。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>126.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>99.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>196.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>119.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>143.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>125.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>147.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>145.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>117.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>102.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.293</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>11</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>3</td>\n",
       "      <td>102.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "      <td>109.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>9</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>13</td>\n",
       "      <td>153.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1.174</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>147.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>187.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6</td>\n",
       "      <td>162.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4</td>\n",
       "      <td>136.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>121.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3</td>\n",
       "      <td>108.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>8</td>\n",
       "      <td>154.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.443</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>128.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>7</td>\n",
       "      <td>137.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>1</td>\n",
       "      <td>106.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>170.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>9</td>\n",
       "      <td>89.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1     2     3      4     5      6   7  8\n",
       "0     6  148.0  72.0  35.0    NaN  33.6  0.627  50  1\n",
       "1     1   85.0  66.0  29.0    NaN  26.6  0.351  31  0\n",
       "2     8  183.0  64.0  23.0   94.0  23.3  0.672  32  1\n",
       "3     1   89.0  66.0  23.0   94.0  28.1  0.167  21  0\n",
       "4     0  137.0  40.0  35.0  168.0  43.1  2.288  33  1\n",
       "5     5  116.0  74.0  32.0   88.0  25.6  0.201  30  0\n",
       "6     3   78.0  50.0  32.0   88.0  31.0  0.248  26  1\n",
       "7    10  115.0  70.0  45.0  543.0  35.3  0.134  29  0\n",
       "8     2  197.0  70.0  45.0  543.0  30.5  0.158  53  1\n",
       "9     8  125.0  96.0   NaN    NaN  37.6  0.232  54  1\n",
       "10    4  110.0  92.0   NaN    NaN  37.6  0.191  30  0\n",
       "11   10  168.0  74.0   NaN    NaN  38.0  0.537  34  1\n",
       "12   10  139.0  80.0  23.0  846.0  27.1  1.441  57  0\n",
       "13    1  189.0  60.0  23.0  846.0  30.1  0.398  59  1\n",
       "14    5  166.0  72.0  19.0  175.0  25.8  0.587  51  1\n",
       "15    7  100.0  84.0  47.0  230.0  30.0  0.484  32  1\n",
       "16    0  118.0  84.0  47.0  230.0  45.8  0.551  31  1\n",
       "17    7  107.0  74.0  38.0   83.0  29.6  0.254  31  1\n",
       "18    1  103.0  30.0  38.0   83.0  43.3  0.183  33  0\n",
       "19    1  115.0  70.0  30.0   96.0  34.6  0.529  32  1\n",
       "20    3  126.0  88.0  41.0  235.0  39.3  0.704  27  0\n",
       "21    8   99.0  84.0   NaN    NaN  35.4  0.388  50  0\n",
       "22    7  196.0  90.0  35.0    NaN  39.8  0.451  41  1\n",
       "23    9  119.0  80.0  35.0  146.0  29.0  0.263  29  1\n",
       "24   11  143.0  94.0  33.0  146.0  36.6  0.254  51  1\n",
       "25   10  125.0  70.0  26.0  115.0  31.1  0.205  41  1\n",
       "26    7  147.0  76.0  15.0  140.0  39.4  0.257  43  1\n",
       "27    1   97.0  66.0  15.0  140.0  23.2  0.487  22  0\n",
       "28   13  145.0  82.0  19.0  110.0  22.2  0.245  57  0\n",
       "29    5  117.0  92.0  26.0    NaN  34.1  0.337  38  0\n",
       "..   ..    ...   ...   ...    ...   ...    ...  .. ..\n",
       "738   2   99.0  60.0  17.0  160.0  36.6  0.453  21  0\n",
       "739   1  102.0  74.0  37.0  150.0  39.5  0.293  42  1\n",
       "740  11  120.0  80.0  37.0  150.0  42.3  0.785  48  1\n",
       "741   3  102.0  44.0  20.0   94.0  30.8  0.400  26  0\n",
       "742   1  109.0  58.0  18.0  116.0  28.5  0.219  22  0\n",
       "743   9  140.0  94.0  37.0  140.0  32.7  0.734  45  1\n",
       "744  13  153.0  88.0  37.0  140.0  40.6  1.174  39  0\n",
       "745  12  100.0  84.0  33.0  105.0  30.0  0.488  46  0\n",
       "746   1  147.0  94.0  41.0   57.0  49.3  0.358  27  1\n",
       "747   1   81.0  74.0  41.0   57.0  46.3  1.096  32  0\n",
       "748   3  187.0  70.0  22.0  200.0  36.4  0.408  36  1\n",
       "749   6  162.0  62.0   NaN    NaN  24.3  0.178  50  1\n",
       "750   4  136.0  70.0  39.0   74.0  31.2  1.182  22  1\n",
       "751   1  121.0  78.0  39.0   74.0  39.0  0.261  28  0\n",
       "752   3  108.0  62.0  24.0  510.0  26.0  0.223  25  0\n",
       "753   0  181.0  88.0  44.0  510.0  43.3  0.222  26  1\n",
       "754   8  154.0  78.0  32.0  110.0  32.4  0.443  45  1\n",
       "755   1  128.0  88.0  39.0  110.0  36.5  1.057  37  1\n",
       "756   7  137.0  90.0  41.0    NaN  32.0  0.391  39  0\n",
       "757   0  123.0  72.0   NaN    NaN  36.3  0.258  52  1\n",
       "758   1  106.0  76.0   NaN    NaN  37.5  0.197  26  0\n",
       "759   6  190.0  92.0  26.0   16.0  35.5  0.278  66  1\n",
       "760   2   88.0  58.0  26.0   16.0  28.4  0.766  22  0\n",
       "761   9  170.0  74.0  31.0    NaN  44.0  0.403  43  1\n",
       "762   9   89.0  62.0  48.0  180.0  22.5  0.142  33  0\n",
       "763  10  101.0  76.0  48.0  180.0  32.9  0.171  63  0\n",
       "764   2  122.0  70.0  27.0  112.0  36.8  0.340  27  0\n",
       "765   5  121.0  72.0  23.0  112.0  26.2  0.245  30  0\n",
       "766   1  126.0  60.0  31.0    NaN  30.1  0.349  47  1\n",
       "767   1   93.0  70.0  31.0    NaN  30.4  0.315  23  0\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.fillna(method='bfill', limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 使用均值填充\n",
    "diabetes_meanfill = diabetes.fillna(diabetes.mean())\n",
    "print(diabetes_meanfill.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn提供了可用于替换缺失值的`imputer()`预处理类。这个类直接在NumPy数组上运行。使用的方法通过`strategy`参数指定，默认为`'mean'`。`fit_transform`方法会训练并填充给定的参数中的数据缺失值。详见[sklearn中的Imputer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html#sklearn.preprocessing.Imputer.fit_transform)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy='mean')\n",
    "diabetes_imputer = imputer.fit_transform(diabetes.values)\n",
    "print(np.isnan(diabetes_imputer).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用填充后的数据训练LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766927083333\n"
     ]
    }
   ],
   "source": [
    "values = diabetes_imputer\n",
    "X = values[:, 0:8]\n",
    "y = values[:, 8]\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 支持丢失值的算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有一些算法可以灵活应对缺失值，例如k-Nearest Neighbors，当值丢失时，它可以将其不计入距离测量。\n",
    "另一些算法，例如分类和回归树，可以在构建预测模型时将丢失值看作唯一且不同的值。\n",
    "遗憾的是，决策树和k-Nearest Neighbors对于丢失值并不友好。\n",
    "不管怎样，如果你考虑使用其他算法（如xgboost）或开发自己的执行，这依然是一个选择。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
